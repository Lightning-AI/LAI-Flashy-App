import sys
import flash
from flash.core.data.utils import download_data
from flash.text import TextClassificationData, TextClassifier
from pytorch_lightning.callbacks.progress.base import ProgressBarBase
from lightning.utilities.state import AppState

app_state = sys.argv[1]

class AppProgressBar(ProgressBarBase):
  def __init__(self):
    super().__init__()

    self._total = 0

  def disable(self):
    pass

  def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
    super().on_train_batch_end(
      trainer, pl_module, outputs, batch, batch_idx
    )
    app_state.progress = (self._total + self.train_batch_idx) / (self.total_train_batches * self.trainer.max_epochs)

  def on_train_epoch_end(self, trainer, pl_module):
    super().on_train_epoch_end(trainer, pl_module)
    self._total += self.total_train_batches

{% if not rendering %}
import os
os.chdir("{{ root }}")
{% endif %}

download_data("{{ url }}", ".")

datamodule = TextClassificationData.{{ method }}(
  {% for key, value in data_config.items() %}{{ key }}={% if value is string %}"{{ value }}"{% else %}{{ value }}{% endif %},{% endfor %}
  input_field="review",
  target_fields="sentiment",
  batch_size=4,
)

model = TextClassifier(backbone="{{ model_config.backbone }}", learning_rate={{ model_config.learning_rate }}, labels=datamodule.labels)

trainer = flash.Trainer(max_epochs=1, limit_train_batches=1, limit_val_batches=1, callbacks=[AppProgressBar()])
trainer.finetune(model, datamodule=datamodule, strategy="freeze")

{% if not rendering %}
import os
trainer.save_checkpoint(os.path.join("{{ root }}", "{{ run_id }}.pt"))
with open(os.path.join("{{ root }}", "{{ run_id }}.txt"), "w") as f:
  f.write(f"{trainer.callback_metrics['val_accuracy']}")
{% endif %}
